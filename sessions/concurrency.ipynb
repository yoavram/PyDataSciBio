{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer science, concurrency is about managing multiple tasks in a program, while parallelism is about actually executing them simultaneously.\n",
    "\n",
    "Here's a breakdown of concurrency:\n",
    "\n",
    "- Multiple tasks: A program is broken down into smaller tasks that can be run independently.\n",
    "- Out-of-order execution: The order in which these tasks are completed isn't necessarily important. As long as the final outcome is correct, it doesn't matter if task B finishes before task A.\n",
    "- Partial order: There might be some dependencies between tasks, requiring a certain level of order. Task B might need the results of task A before it can start.\n",
    "\n",
    "There are several benefits to using concurrency:\n",
    "\n",
    "- Improved responsiveness: If a program encounters a long-running task, concurrency allows it to continue working on other tasks while waiting. This makes the program feel more responsive to the user.\n",
    "- Efficient resource utilization: By keeping the processor busy with multiple tasks, concurrency can improve overall performance.\n",
    "\n",
    "However, concurrency also introduces challenges:\n",
    "\n",
    "- Coordination: When multiple tasks are accessing shared resources, there's a risk of conflicts. Careful coordination is needed to ensure data consistency and prevent issues like deadlocks.\n",
    "- Complexity: Reasoning about concurrent programs can be difficult. The out-of-order execution can lead to unexpected behavior if not managed properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deadlock 1](../data/images/deadlock.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deadlock 2](../data/images/deadlock_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading\n",
    "\n",
    "Threads are very useful for maintaining multiple program flows running (quasi-)simultaneously. \n",
    "In Python, threads are real system threads and are managed by the operating system.\n",
    "\n",
    "But CPython, the standard Python implementation, is not thread-safe, so the [Global Interperter Lock (**GIL**)](http://www.dabeaz.com/GIL) allows only one thread to execute at any given time. Therefore, the main benefit from threading is that one waiting job (I/O, sleep, waiting for user event) doesn't block other jobs from running. Or as the saying goes, threads are good for doing nothing: waiting mostly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the GIL for Biology Students\n",
    "\n",
    "Imagine you have a lab with a single, very expensive microscope that everyone needs to use. The Global Interpreter Lock (GIL) in Python works similarly to how you might manage this shared resource.\n",
    "\n",
    "## The Single-Microscope Lab Analogy\n",
    "\n",
    "In your biology lab:\n",
    "\n",
    "1. **The Microscope = Your Computer's Processor**: Just as there's only one high-powered microscope, Python's GIL only allows one thread to execute Python code at a time.\n",
    "\n",
    "2. **Lab Researchers = Python Threads**: Multiple researchers (threads) want to use the microscope (processor) simultaneously to work on different samples.\n",
    "\n",
    "3. **Lab Protocol = GIL Management**: You implement a rule where each researcher can only use the microscope for 5 minutes before they must let someone else have a turn, even if they're not finished with their work.\n",
    "\n",
    "## How It Works in Practice\n",
    "\n",
    "When a Python program with multiple threads runs:\n",
    "\n",
    "1. **Taking Turns**: Just like biologists taking turns with the microscope, Python threads take turns executing code by acquiring and releasing the GIL.\n",
    "\n",
    "2. **Waiting Room**: When one thread is \"looking through the microscope\" (holding the GIL), the other threads wait in line.\n",
    "\n",
    "3. **Time-Sharing**: After a brief period, Python forces the active thread to release the GIL so another thread can have a turn, even if the first thread isn't finished.\n",
    "\n",
    "## Two Types of Lab Work\n",
    "\n",
    "In your biology lab, researchers do two types of work:\n",
    "\n",
    "1. **Sample Analysis (CPU-bound)**: Looking at slides under the microscope, which requires active use of the microscope the entire time.\n",
    "\n",
    "2. **Sample Preparation (I/O-bound)**: Preparing slides, retrieving samples from storage, or waiting for chemical reactions - tasks that don't require the microscope.\n",
    "\n",
    "Similarly, Python tasks fall into two categories:\n",
    "\n",
    "1. **CPU-bound tasks**: Calculations, data processing, and analysis that need active processor time.\n",
    "\n",
    "2. **I/O-bound tasks**: Reading/writing files, network operations, or waiting for user input - tasks that involve waiting.\n",
    "\n",
    "## Why Threading Still Helps Sometimes\n",
    "\n",
    "Imagine a researcher who needs to look at a slide for 10 seconds, then wait 50 seconds for a chemical reaction, then look at it again. While they're waiting for the reaction, they don't need the microscope!\n",
    "\n",
    "In Python:\n",
    "- When a thread is waiting for I/O (like downloading data), it voluntarily releases the GIL\n",
    "- Other threads can use the processor during this waiting time\n",
    "- This is why threading helps with I/O-bound tasks, even with the GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Simple example\n",
    "\n",
    "A worker thread that counts from 1 to 10, waiting one second between numbers, but doesn't block the main thread that counts from 11 to 20 (also waiting). \n",
    "\n",
    "We use the [threading](https://docs.python.org/3.5/library/threading.html) module from the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def task(start, end):\n",
    "    for i in range(start, end):\n",
    "        print(\" {} \".format(i), end=\"\", flush=True)\n",
    "        time.sleep(1)\n",
    "\n",
    "worker = threading.Thread(target=task, args=(1, 10))\n",
    "worker.start()\n",
    "task(11, 20)\n",
    "worker.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O bounded programs\n",
    "\n",
    "When we do any kind of I/O, the GIL is released as soon as control is given to the OS or to lower-level C code. So threads are great for concurrency in I/O bounded programs, because as one thread waits for I/O, other threads can go on doing their jobs, as the GIL is released. This is true as long as I/O is not very quick and there are not too many concurrent jobs; if there are many concurrent short jobs, they will start a [GIL war](http://www.dabeaz.com/GIL/), which is bad for performence.\n",
    "\n",
    "Let's start with a synchrounous program that reads books from the Gutenberg project and finds the most common word. Finding the most common word takes a while, but a lot less than reading the data from the web, so this is definately an I/O-bounded program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import urllib.request\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download and parse a [set of stop words](https://github.com/Alir3z4/stop-words/raw/25c6a0aea665871e887f155b883e950c3743ce50/english.txt) not to be included in the analysis:\n",
    "\n",
    "For this we use `urlopen` which opens a remote URL as if it was a file, allowing us to read line-by-line. We then `decode` each line, as `urlopen` reads data as `bytes` rather than `str`, and `decode` wil decode those bytes to a string. \n",
    "We then use `strip` to remove whitespace. `words` is therefore a generator expression on the single lines in the URL, each a word; we thus consume the generator with the constructor of `frozenset`, an immutable set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_url = 'https://github.com/Alir3z4/stop-words/raw/25c6a0aea665871e887f155b883e950c3743ce50/english.txt'\n",
    "\n",
    "with urllib.request.urlopen(stop_words_url) as f:\n",
    "    words = (line.decode().strip() for line in f)\n",
    "    stop_words = frozenset(words)\n",
    "\n",
    "print(list(stop_words)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read a bunch of books (see `names`) and parse them for the most common word (`most_common_word`).\n",
    "\n",
    "First, create a tuple of the book names, and a dictionary that maps book names to book URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\n",
    "    'Gulliver',\n",
    "    'Alice in Wonderland',\n",
    "    'Pride and prejudice',\n",
    "    'Yellow wallpaper',\n",
    "    'Metamorphosis',\n",
    "    'A Tale of Two Cities',\n",
    "    'The Importance of Being Earnest',\n",
    "    'Frankenstein'\n",
    ")\n",
    "url_template = 'https://raw.githubusercontent.com/yoavram/Py4Eng/master/data/{}.txt'\n",
    "urls = {\n",
    "    name: urllib.parse.quote(url_template.format(name), safe=\":/\") \n",
    "    for name in names\n",
    "}\n",
    "print('Gulliver:', urls['Gulliver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `most_cmmon_word` function accepts a `book_item` which is a tuple of `(name, url)`, opens the URL for reading, reads the \"file\" line-by-line, and for each line it decodes, strips, lowers, and splits. Therefore, each lines is converted to a list of lowercase words.\n",
    "These words are then added to a `Counter` object, which is similar to a `set`, only it remembers **how many times** each element was added, and it allows to query about number of occurences and most common elements.\n",
    "\n",
    "The function returns the name of the book, the most common word, and the count for the most common word, after zeroing the count for stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_word(book_item):\n",
    "    name, url = book_item\n",
    "    counter = Counter()\n",
    "    with urllib.request.urlopen(url) as f:        \n",
    "        for line in f:\n",
    "            if not line:\n",
    "                break\n",
    "            line = line.decode().strip().lower().split()\n",
    "            counter.update(line)\n",
    "    for word in stop_words:\n",
    "        counter[word] = 0\n",
    "    word, count = counter.most_common(1)[0] # [0] gives only the first most common word\n",
    "    return name, word, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_word(list(urls.items())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple [context manager](https://docs.python.org/3.5/library/contextlib.html) for measuring time (`%timeit` is less useful for concurrency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def tictoc():\n",
    "    tic = time.time()\n",
    "    yield\n",
    "    toc = time.time()\n",
    "    print(\"Elapsed time: {:.2f} seconds\".format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    print(\"hey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential run\n",
    "\n",
    "We start by running the analysis in sequence using a single thread to get a baseline.\n",
    "\n",
    "Note that a `map` applies a function to elements of an iterable using lazy evaluation\n",
    "\n",
    "```python\n",
    "results = map(most_common_word, urls.items())\n",
    "```\n",
    "\n",
    "very similar to the generator expression\n",
    "\n",
    "```python\n",
    "results = (most_common_word(item) for item in urls.items())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_map = map(lambda x: x**3, [1,2,3])\n",
    "print(list(cube_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    results = map(most_common_word, urls.items())\n",
    "    for name, word, count in results:\n",
    "        print('Most common word in {} is \"{}\" ({} appearances)'.format(name, word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-threading\n",
    "\n",
    "To run a multi-threaded version of the above, we could use `threading` and create our threads etc., but there is a lot of boilerplate. This boilerplate can be handeled by a thread pool from the [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) module.\n",
    "The thread pool executor is created using a context manager, so that all the threads in the pool will be closed when we are done.\n",
    "Using the executor is really easy if we already used the `map` pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "n_workers = len(urls)\n",
    "\n",
    "with tictoc():\n",
    "    with concurrent.futures.ThreadPoolExecutor(n_workers) as executor:\n",
    "        results = executor.map(most_common_word, urls.items())\n",
    "        for name, word, count in results:\n",
    "            print('Most common word in {} is \"{}\" ({} appearances)'.format(name, word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, almost 5-fold improvement in running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the futures?\n",
    "\n",
    "The module is called `concurrent.futures` and in the documentation you can read that you are actually creating `Future` objects. These are like promises - they represent computational tasks that will be completed; therefore, they allow for an asynchronous style of programming, as we can start a task, go on to do something else, and then either check if it finished, wait for it to finish, or a assign a callback to be called when it is finished.\n",
    "\n",
    "In the above, the `Future`s were handled by the executor `map` function, which creates `Future`s and waits for them to finish working. Now we will use them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    with concurrent.futures.ThreadPoolExecutor(n_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(most_common_word, item) \n",
    "            for item in urls.items()\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            name, word, count = future.result()\n",
    "            print('Most common word in {} is \"{}\" ({} appearances)'.format(name, word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `as_completed` allows us to iterate over the futures as they are completed, i.e. in roughly the order they finished their tasks, rather the order they were created (which is the case in the previous example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU bounded program\n",
    "\n",
    "In some cases running multiple threads actually helps even if we are in a CPU bounded scenario, because the OS may run these threads on separate cores, and **if the code that we use releases the GIL** in some way, then we can achieve \"true multi-threading\". Note: if the code doesn't release the GIL, we will get into a [GIL war](http://www.dabeaz.com/GIL/) and performance will suffer compared to a single-core single-thread program!\n",
    "\n",
    "In the following example we calculate a hash of our books using the *very slow* function, `pbkdf2_hmac`. The [`haslib` docs](https://docs.python.org/3/library/hashlib.html) specify that if the data is larger than 2047 bit, **the GIL is released** (the computation is done in C, so the GIL can be explicitly released) and therefore if we use threads we will see an improvement on multi-core machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import binascii\n",
    "import concurrent.futures\n",
    "import time\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if the number of CPUs is 1 (see last command in previous cell), we won't get any benefit from a multi-threading approach - on the contrary.\n",
    "\n",
    "We start by reading books to memory so that I/O won't be an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = (\n",
    "    'Gulliver',\n",
    "    'Alice in Wonderland',\n",
    "    'Pride and prejudice',\n",
    "    'Yellow wallpaper',\n",
    "    'Metamorphosis',\n",
    "    'The Importance of Being Earnest'\n",
    ")\n",
    "filenames = {\n",
    "    name: '../data/books/{}.txt'.format(name) \n",
    "    for name in names\n",
    "}\n",
    "print('Gulliver:', filenames['Gulliver'])\n",
    "\n",
    "def read_book(item):\n",
    "    name, filename = item    \n",
    "    with open(filename) as f:\n",
    "        data = f.read()        \n",
    "    return name, data\n",
    "\n",
    "books = dict(read_book(item) for item in filenames.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hash_book` is a **slow** function that takes an entire book and performs a specific [hash function](https://docs.python.org/3/library/hashlib.html#hashlib.pbkdf2_hmac) on it with multiple iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_book(item):\n",
    "    name, data = item    \n",
    "    # very slow function\n",
    "    fingerprint = hashlib.pbkdf2_hmac('sha512', data.encode('utf8'), b'salt', 1000000)\n",
    "    return name, binascii.hexlify(fingerprint).decode()\n",
    "\n",
    "%timeit -n 3 hash_book(('Gulliver', books['Gulliver']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential\n",
    "\n",
    "Running in a single-thread mode - open your process monitor to see that only one core is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    results = map(hash_book, books.items())\n",
    "    for name, fingerprint in results:\n",
    "        print('Fingerprint for {} is \"{}\"'.format(name, fingerprint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-threaded\n",
    "\n",
    "In multi-thread mode, you'll see that all the cores are used, at least on some OS (it is OS-dependent, and requires multiple cores):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(\n",
    "            hash_book, books.items()\n",
    "        )\n",
    "        for name, fingerprint in results:\n",
    "            print('Fingerprint for {} is \"{}\"'.format(name, fingerprint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `concurrent.futures` module has another pool executor - a `ProcessPoolExecutor` that uses processes for the jobs. It's as easy to use as the `ThreadPoolExecutor`, but in this case no further improvement can be had by replacing `ThreadPoolExecutor` with `ProcessPoolExecutor`, at least on my machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-processing\n",
    "\n",
    "From the [threading](https://docs.python.org/3/library/threading.html) module:\n",
    "> CPython implementation detail: In CPython, due to the Global Interpreter Lock, **only one thread can execute Python code at once**... If you want your application to make better use of the **computational resources of multi-core machines**, you are advised to use `multiprocessing` or `concurrent.futures.ProcessPoolExecutor`.\n",
    "\n",
    "The standard library module, [multiprocessing](https://docs.python.org/3/library/multiprocessing.html), provides low-level interfaces for the use of multiple processes. \n",
    "\n",
    "We will use [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) which provides a high-level API - a process pool. If you get a persistent error about broken processes, try to restart the kernel and possibly the notebook server, then debug without the executor (non-parallel) and when it works, re-insert the executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "primes = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419,\n",
    "    3399726899288419,\n",
    "    1125828054422712,\n",
    "    237397848077029,\n",
    "]\n",
    "\n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    results = map(\n",
    "        is_prime, primes\n",
    "    )\n",
    "    for n, p in zip(primes, results):\n",
    "        print('{} is prime: {}'.format(n, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tictoc():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(\n",
    "            is_prime, primes\n",
    "        )\n",
    "        for n, p in zip(primes, results):\n",
    "            print('{} is prime: {}'.format(n, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "with tictoc():\n",
    "    with Pool() as p:\n",
    "        results = p.map(is_prime, primes)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Multiprocessing\" Solution:\n",
    "\n",
    "If your lab really needs multiple microscopes running simultaneously, you'd buy more microscopes.\n",
    "\n",
    "Similarly, Python's multiprocessing module creates multiple separate Python processes, each with its own GIL. This is like having multiple complete labs, each with its own microscope. It requires more resources but allows true parallel execution for CPU-intensive tasks.\n",
    "\n",
    "## Why Does the GIL Exist?\n",
    "\n",
    "The GIL exists primarily for memory safety. Just as lab protocols prevent sample contamination, the GIL prevents memory corruption in CPython's memory management system, making the code safer and more reliable.\n",
    "\n",
    "## Practical Implications\n",
    "\n",
    "When deciding between threading and multiprocessing in Python, ask yourself:\n",
    "\n",
    "- **Am I mostly waiting?** (I/O-bound) ‚Üí Use threading\n",
    "- **Am I mostly calculating?** (CPU-bound) ‚Üí Use multiprocessing\n",
    "\n",
    "Or to continue our analogy:\n",
    "\n",
    "- \"Am I spending more time actively using the microscope, or am I spending more time waiting for other things to happen?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![thread vs process](https://i.ytimg.com/vi/4rLW7zg21gI/maxresdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü™ê Zorgian Research Lab I/O vs CPU Exercise\n",
    "**Time**: ~5 minutes\n",
    "\n",
    "**Background**:  \n",
    "Zorgian scientists are optimizing their research processes using Earth's Python programming. They need to understand how different types of tasks affect concurrent processing.\n",
    "\n",
    "**Task**:  \n",
    "Implement and compare the performance of I/O-bound tasks (like reading research files) versus CPU-bound tasks (like analyzing genetic sequences) using both sequential and threaded approaches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "def io_bound_task():\n",
    "    # Simulating reading from a Zorgian data repository\n",
    "    print(\"Reading Zorgian specimen data...\")\n",
    "    time.sleep(1)  # Simulates I/O wait time\n",
    "    print(\"I/O task completed\")\n",
    "\n",
    "def cpu_bound_task():\n",
    "    # Simulating Zorgian genetic sequence analysis\n",
    "    print(\"Analyzing Zorgian DNA sequence...\")\n",
    "    result = 0\n",
    "    for i in range(1000000):  # Computationally intensive task\n",
    "        result += i\n",
    "    print(\"CPU task completed\")\n",
    "\n",
    "# Sequential execution\n",
    "def run_sequential():\n",
    "    start = time.time()\n",
    "    for _ in range(4):\n",
    "        io_bound_task()\n",
    "    for _ in range(4):\n",
    "        cpu_bound_task()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Threaded execution\n",
    "def run_threaded():\n",
    "    start = time.time()\n",
    "    threads = []\n",
    "    for _ in range(4):\n",
    "        t = threading.Thread(target=io_bound_task)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "    threads = []\n",
    "    for _ in range(4):\n",
    "        t = threading.Thread(target=cpu_bound_task)\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Compare execution times\n",
    "sequential_time = run_sequential()\n",
    "print(f\"Sequential execution: {sequential_time:.2f} seconds\")\n",
    "\n",
    "threaded_time = run_threaded()\n",
    "print(f\"Threaded execution: {threaded_time:.2f} seconds\")\n",
    "\n",
    "print(f\"Speedup for I/O: Significant\")\n",
    "print(f\"Speedup for CPU: Minimal due to GIL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ü™ê Zorgian Biological Sample Analysis\n",
    "**Time**: ~5 minutes\n",
    "\n",
    "**Background**:  \n",
    "Zorgian biologists collected samples from various ecosystems and need to process them quickly to prevent degradation.\n",
    "\n",
    "**Task**:  \n",
    "Process multiple biological samples concurrently using thread pooling and compare with sequential processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "import random\n",
    "\n",
    "def process_zorgian_sample(sample_id):\n",
    "    \"\"\"Process a Zorgian biological sample\"\"\"\n",
    "    print(f\"Processing sample {sample_id}...\")\n",
    "    # Simulate varying processing times based on sample complexity\n",
    "    processing_time = random.uniform(0.5, 1.5)\n",
    "    time.sleep(processing_time)\n",
    "    microbe_count = random.randint(1, 100)\n",
    "    return f\"Sample {sample_id}: {microbe_count} zorgian microbes detected\"\n",
    "\n",
    "# Samples collected from various Zorgian ecosystems\n",
    "zorgian_samples = list(range(1, 11))  # 10 samples to process\n",
    "\n",
    "# Sequential processing\n",
    "def process_sequentially():\n",
    "    start = time.time()\n",
    "    results = []\n",
    "    for sample in zorgian_samples:\n",
    "        results.append(process_zorgian_sample(sample))\n",
    "    end = time.time()\n",
    "    return results, end - start\n",
    "\n",
    "# Concurrent processing\n",
    "def process_concurrently():\n",
    "    start = time.time()\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(process_zorgian_sample, zorgian_samples))\n",
    "    end = time.time()\n",
    "    return results, end - start\n",
    "\n",
    "# Compare methods\n",
    "seq_results, seq_time = process_sequentially()\n",
    "conc_results, conc_time = process_concurrently()\n",
    "\n",
    "print(f\"Sequential processing: {seq_time:.2f} seconds\")\n",
    "print(f\"Concurrent processing: {conc_time:.2f} seconds\")\n",
    "print(f\"Speedup factor: {seq_time/conc_time:.2f}x\")\n",
    "\n",
    "# Print a few results\n",
    "for i in range(3):\n",
    "    print(seq_results[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ü™ê Zorgian Laboratory Deadlock Detector\n",
    "**Time**: ~5 minutes\n",
    "\n",
    "**Background**:  \n",
    "Two Zorgian researchers are working in the same laboratory and need to share limited equipment. If they don't coordinate properly, they might create a deadlock.\n",
    "\n",
    "**Task**:  \n",
    "Identify and fix the deadlock in the shared laboratory equipment access code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Shared laboratory equipment\n",
    "microscope = threading.Lock()\n",
    "centrifuge = threading.Lock()\n",
    "\n",
    "def zorgian_researcher_1():\n",
    "    \"\"\"First researcher's procedure\"\"\"\n",
    "    print(\"Researcher 1 starting experiment...\")\n",
    "    with microscope:\n",
    "        print(\"Researcher 1 acquired the microscope\")\n",
    "        time.sleep(0.1)  # Preparing sample\n",
    "        print(\"Researcher 1 waiting for centrifuge\")\n",
    "        with centrifuge:\n",
    "            print(\"Researcher 1 acquired the centrifuge\")\n",
    "            print(\"Researcher 1 completed their experiment\")\n",
    "\n",
    "def zorgian_researcher_2():\n",
    "    \"\"\"Second researcher's procedure\"\"\"\n",
    "    print(\"Researcher 2 starting experiment...\")\n",
    "    with centrifuge:\n",
    "        print(\"Researcher 2 acquired the centrifuge\")\n",
    "        time.sleep(0.1)  # Preparing sample\n",
    "        print(\"Researcher 2 waiting for microscope\")\n",
    "        with microscope:\n",
    "            print(\"Researcher 2 acquired the microscope\")\n",
    "            print(\"Researcher 2 completed their experiment\")\n",
    "\n",
    "# This will cause a deadlock\n",
    "def run_with_deadlock():\n",
    "    t1 = threading.Thread(target=zorgian_researcher_1)\n",
    "    t2 = threading.Thread(target=zorgian_researcher_2)\n",
    "    \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "# Solution: Fix the order of resource acquisition\n",
    "def zorgian_researcher_2_fixed():\n",
    "    \"\"\"Second researcher's procedure with fixed resource order\"\"\"\n",
    "    print(\"Researcher 2 starting experiment (fixed)...\")\n",
    "    with microscope:  # Acquire resources in the same order as researcher 1\n",
    "        print(\"Researcher 2 acquired the microscope\")\n",
    "        time.sleep(0.1)  # Preparing sample\n",
    "        with centrifuge:\n",
    "            print(\"Researcher 2 acquired the centrifuge\")\n",
    "            print(\"Researcher 2 completed their experiment\")\n",
    "\n",
    "def run_fixed():\n",
    "    t1 = threading.Thread(target=zorgian_researcher_1)\n",
    "    t2 = threading.Thread(target=zorgian_researcher_2_fixed)\n",
    "    \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "\n",
    "# Uncomment to demonstrate deadlock (caution: will hang)\n",
    "# run_with_deadlock()\n",
    "\n",
    "# Run the fixed version\n",
    "print(\"Running with fixed resource ordering:\")\n",
    "run_fixed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ü™ê Zorgian Calendar API Simulation\n",
    "**Time**: ~5 minutes\n",
    "\n",
    "**Background**:  \n",
    "The Zorgian Calendar Authority needs to process multiple calendar conversion requests simultaneously for interplanetary communications.\n",
    "\n",
    "**Task**:  \n",
    "Create a simulated Zorgian Calendar API that can handle multiple concurrent requests using threads.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "import queue\n",
    "from datetime import datetime\n",
    "\n",
    "# Simulated request queue\n",
    "request_queue = queue.Queue()\n",
    "\n",
    "def zorgian_calendar_conversion(earth_date):\n",
    "    \"\"\"Convert Earth date to Zorgian date format\"\"\"\n",
    "    # Simulating complex calculation\n",
    "    time.sleep(random.uniform(0.2, 0.5))\n",
    "    \n",
    "    # Simple conversion algorithm (for demonstration)\n",
    "    year = earth_date.year + 3761  # Base Zorgian year offset\n",
    "    moon_cycle = (earth_date.month * 29 + earth_date.day) % 30\n",
    "    zorg_time = earth_date.hour\n",
    "    \n",
    "    return f\"Year {year}, Moon Cycle {moon_cycle}, Zorg {zorg_time}\"\n",
    "\n",
    "def process_requests(worker_id):\n",
    "    \"\"\"Worker thread to process calendar conversion requests\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Get a request with a timeout\n",
    "            earth_date, request_id = request_queue.get(timeout=2)\n",
    "            \n",
    "            print(f\"Worker {worker_id} processing request {request_id}...\")\n",
    "            zorgian_date = zorgian_calendar_conversion(earth_date)\n",
    "            \n",
    "            print(f\"Worker {worker_id} completed request {request_id}: {earth_date} ‚Üí {zorgian_date}\")\n",
    "            request_queue.task_done()\n",
    "            \n",
    "        except queue.Empty:\n",
    "            print(f\"Worker {worker_id} shutting down - no more requests\")\n",
    "            break\n",
    "\n",
    "# Generate some sample requests\n",
    "for i in range(10):\n",
    "    # Generate random Earth dates\n",
    "    year = random.randint(2000, 2025)\n",
    "    month = random.randint(1, 12)\n",
    "    day = random.randint(1, 28)\n",
    "    hour = random.randint(0, 23)\n",
    "    \n",
    "    earth_date = datetime(year, month, day, hour)\n",
    "    request_queue.put((earth_date, i+1))\n",
    "\n",
    "# Create worker threads\n",
    "workers = []\n",
    "for i in range(4):  # 4 worker threads\n",
    "    t = threading.Thread(target=process_requests, args=(i+1,))\n",
    "    t.daemon = True  # Allow the program to exit even if threads are running\n",
    "    workers.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all requests to be processed\n",
    "request_queue.join()\n",
    "print(\"All calendar conversion requests completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
